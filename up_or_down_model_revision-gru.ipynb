{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>start</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>end</th>\n",
       "      <th>volume</th>\n",
       "      <th>foreign</th>\n",
       "      <th>person</th>\n",
       "      <th>company</th>\n",
       "      <th>wondollar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020.3.25</td>\n",
       "      <td>48950</td>\n",
       "      <td>49600</td>\n",
       "      <td>47150</td>\n",
       "      <td>48650</td>\n",
       "      <td>52735922</td>\n",
       "      <td>-2751527</td>\n",
       "      <td>4980190</td>\n",
       "      <td>-1695448</td>\n",
       "      <td>1229.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.3.24</td>\n",
       "      <td>43850</td>\n",
       "      <td>46950</td>\n",
       "      <td>43050</td>\n",
       "      <td>46950</td>\n",
       "      <td>49801908</td>\n",
       "      <td>2929769</td>\n",
       "      <td>-6174614</td>\n",
       "      <td>3254324</td>\n",
       "      <td>1249.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.3.23</td>\n",
       "      <td>42600</td>\n",
       "      <td>43550</td>\n",
       "      <td>42400</td>\n",
       "      <td>42500</td>\n",
       "      <td>41701626</td>\n",
       "      <td>-8143293</td>\n",
       "      <td>10988297</td>\n",
       "      <td>-3248991</td>\n",
       "      <td>1266.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.3.20</td>\n",
       "      <td>44150</td>\n",
       "      <td>45500</td>\n",
       "      <td>43550</td>\n",
       "      <td>45400</td>\n",
       "      <td>49730008</td>\n",
       "      <td>-5133212</td>\n",
       "      <td>3248749</td>\n",
       "      <td>1669124</td>\n",
       "      <td>1246.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.3.19</td>\n",
       "      <td>46400</td>\n",
       "      <td>46650</td>\n",
       "      <td>42300</td>\n",
       "      <td>42950</td>\n",
       "      <td>56925513</td>\n",
       "      <td>-5807616</td>\n",
       "      <td>4105594</td>\n",
       "      <td>1612440</td>\n",
       "      <td>1285.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>2017.10.23</td>\n",
       "      <td>54600</td>\n",
       "      <td>54640</td>\n",
       "      <td>54000</td>\n",
       "      <td>54300</td>\n",
       "      <td>8311050</td>\n",
       "      <td>30468</td>\n",
       "      <td>4568</td>\n",
       "      <td>-63065</td>\n",
       "      <td>1130.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2017.10.20</td>\n",
       "      <td>52800</td>\n",
       "      <td>54100</td>\n",
       "      <td>52800</td>\n",
       "      <td>53840</td>\n",
       "      <td>8027050</td>\n",
       "      <td>29906</td>\n",
       "      <td>-2283</td>\n",
       "      <td>-39735</td>\n",
       "      <td>1131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>2017.10.19</td>\n",
       "      <td>54700</td>\n",
       "      <td>54700</td>\n",
       "      <td>52980</td>\n",
       "      <td>52980</td>\n",
       "      <td>12108700</td>\n",
       "      <td>-19892</td>\n",
       "      <td>46171</td>\n",
       "      <td>-46270</td>\n",
       "      <td>1132.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>2017.10.18</td>\n",
       "      <td>54820</td>\n",
       "      <td>55240</td>\n",
       "      <td>54040</td>\n",
       "      <td>54760</td>\n",
       "      <td>10110750</td>\n",
       "      <td>8951</td>\n",
       "      <td>-3285</td>\n",
       "      <td>-23873</td>\n",
       "      <td>1129.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>2017.10.17</td>\n",
       "      <td>54020</td>\n",
       "      <td>55380</td>\n",
       "      <td>54000</td>\n",
       "      <td>54800</td>\n",
       "      <td>10607800</td>\n",
       "      <td>34020</td>\n",
       "      <td>-15898</td>\n",
       "      <td>-35696</td>\n",
       "      <td>1132.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  start   high    low    end    volume  foreign    person  \\\n",
       "0     2020.3.25  48950  49600  47150  48650  52735922 -2751527   4980190   \n",
       "1     2020.3.24  43850  46950  43050  46950  49801908  2929769  -6174614   \n",
       "2     2020.3.23  42600  43550  42400  42500  41701626 -8143293  10988297   \n",
       "3     2020.3.20  44150  45500  43550  45400  49730008 -5133212   3248749   \n",
       "4     2020.3.19  46400  46650  42300  42950  56925513 -5807616   4105594   \n",
       "..          ...    ...    ...    ...    ...       ...      ...       ...   \n",
       "592  2017.10.23  54600  54640  54000  54300   8311050    30468      4568   \n",
       "593  2017.10.20  52800  54100  52800  53840   8027050    29906     -2283   \n",
       "594  2017.10.19  54700  54700  52980  52980  12108700   -19892     46171   \n",
       "595  2017.10.18  54820  55240  54040  54760  10110750     8951     -3285   \n",
       "596  2017.10.17  54020  55380  54000  54800  10607800    34020    -15898   \n",
       "\n",
       "     company  wondollar  \n",
       "0   -1695448     1229.9  \n",
       "1    3254324     1249.6  \n",
       "2   -3248991     1266.5  \n",
       "3    1669124     1246.5  \n",
       "4    1612440     1285.7  \n",
       "..       ...        ...  \n",
       "592   -63065     1130.2  \n",
       "593   -39735     1131.0  \n",
       "594   -46270     1132.4  \n",
       "595   -23873     1129.9  \n",
       "596   -35696     1132.5  \n",
       "\n",
       "[597 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gru-10days\n",
    "#인풋데이터가 잘못되어 revision \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "'''\n",
    "data preprocessing\n",
    "'''\n",
    "\n",
    "#주가데이터 파일을 로드\n",
    "csv_data = pd.read_csv(\"./data/005930_200325.csv\")\n",
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>end</th>\n",
       "      <th>volume</th>\n",
       "      <th>foreign</th>\n",
       "      <th>person</th>\n",
       "      <th>company</th>\n",
       "      <th>wondollar</th>\n",
       "      <th>price_change_rate</th>\n",
       "      <th>candle_end_start</th>\n",
       "      <th>candle_high_low</th>\n",
       "      <th>up_or_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48950</td>\n",
       "      <td>49600</td>\n",
       "      <td>47150</td>\n",
       "      <td>48650</td>\n",
       "      <td>52735922</td>\n",
       "      <td>-2751527</td>\n",
       "      <td>4980190</td>\n",
       "      <td>-1695448</td>\n",
       "      <td>1229.9</td>\n",
       "      <td>3.620873</td>\n",
       "      <td>-300</td>\n",
       "      <td>2450</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43850</td>\n",
       "      <td>46950</td>\n",
       "      <td>43050</td>\n",
       "      <td>46950</td>\n",
       "      <td>49801908</td>\n",
       "      <td>2929769</td>\n",
       "      <td>-6174614</td>\n",
       "      <td>3254324</td>\n",
       "      <td>1249.6</td>\n",
       "      <td>10.470588</td>\n",
       "      <td>3100</td>\n",
       "      <td>3900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42600</td>\n",
       "      <td>43550</td>\n",
       "      <td>42400</td>\n",
       "      <td>42500</td>\n",
       "      <td>41701626</td>\n",
       "      <td>-8143293</td>\n",
       "      <td>10988297</td>\n",
       "      <td>-3248991</td>\n",
       "      <td>1266.5</td>\n",
       "      <td>-6.387665</td>\n",
       "      <td>-100</td>\n",
       "      <td>1150</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44150</td>\n",
       "      <td>45500</td>\n",
       "      <td>43550</td>\n",
       "      <td>45400</td>\n",
       "      <td>49730008</td>\n",
       "      <td>-5133212</td>\n",
       "      <td>3248749</td>\n",
       "      <td>1669124</td>\n",
       "      <td>1246.5</td>\n",
       "      <td>5.704307</td>\n",
       "      <td>1250</td>\n",
       "      <td>1950</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46400</td>\n",
       "      <td>46650</td>\n",
       "      <td>42300</td>\n",
       "      <td>42950</td>\n",
       "      <td>56925513</td>\n",
       "      <td>-5807616</td>\n",
       "      <td>4105594</td>\n",
       "      <td>1612440</td>\n",
       "      <td>1285.7</td>\n",
       "      <td>-5.811404</td>\n",
       "      <td>-3450</td>\n",
       "      <td>4350</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>54600</td>\n",
       "      <td>54640</td>\n",
       "      <td>54000</td>\n",
       "      <td>54300</td>\n",
       "      <td>8311050</td>\n",
       "      <td>30468</td>\n",
       "      <td>4568</td>\n",
       "      <td>-63065</td>\n",
       "      <td>1130.2</td>\n",
       "      <td>0.854383</td>\n",
       "      <td>-300</td>\n",
       "      <td>640</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>52800</td>\n",
       "      <td>54100</td>\n",
       "      <td>52800</td>\n",
       "      <td>53840</td>\n",
       "      <td>8027050</td>\n",
       "      <td>29906</td>\n",
       "      <td>-2283</td>\n",
       "      <td>-39735</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>1.623254</td>\n",
       "      <td>1040</td>\n",
       "      <td>1300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>54700</td>\n",
       "      <td>54700</td>\n",
       "      <td>52980</td>\n",
       "      <td>52980</td>\n",
       "      <td>12108700</td>\n",
       "      <td>-19892</td>\n",
       "      <td>46171</td>\n",
       "      <td>-46270</td>\n",
       "      <td>1132.4</td>\n",
       "      <td>-3.250548</td>\n",
       "      <td>-1720</td>\n",
       "      <td>1720</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>54820</td>\n",
       "      <td>55240</td>\n",
       "      <td>54040</td>\n",
       "      <td>54760</td>\n",
       "      <td>10110750</td>\n",
       "      <td>8951</td>\n",
       "      <td>-3285</td>\n",
       "      <td>-23873</td>\n",
       "      <td>1129.9</td>\n",
       "      <td>-0.072993</td>\n",
       "      <td>-60</td>\n",
       "      <td>1200</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>54020</td>\n",
       "      <td>55380</td>\n",
       "      <td>54000</td>\n",
       "      <td>54800</td>\n",
       "      <td>10607800</td>\n",
       "      <td>34020</td>\n",
       "      <td>-15898</td>\n",
       "      <td>-35696</td>\n",
       "      <td>1132.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>780</td>\n",
       "      <td>1380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start   high    low    end    volume  foreign    person  company  \\\n",
       "0    48950  49600  47150  48650  52735922 -2751527   4980190 -1695448   \n",
       "1    43850  46950  43050  46950  49801908  2929769  -6174614  3254324   \n",
       "2    42600  43550  42400  42500  41701626 -8143293  10988297 -3248991   \n",
       "3    44150  45500  43550  45400  49730008 -5133212   3248749  1669124   \n",
       "4    46400  46650  42300  42950  56925513 -5807616   4105594  1612440   \n",
       "..     ...    ...    ...    ...       ...      ...       ...      ...   \n",
       "592  54600  54640  54000  54300   8311050    30468      4568   -63065   \n",
       "593  52800  54100  52800  53840   8027050    29906     -2283   -39735   \n",
       "594  54700  54700  52980  52980  12108700   -19892     46171   -46270   \n",
       "595  54820  55240  54040  54760  10110750     8951     -3285   -23873   \n",
       "596  54020  55380  54000  54800  10607800    34020    -15898   -35696   \n",
       "\n",
       "     wondollar  price_change_rate  candle_end_start  candle_high_low  \\\n",
       "0       1229.9           3.620873              -300             2450   \n",
       "1       1249.6          10.470588              3100             3900   \n",
       "2       1266.5          -6.387665              -100             1150   \n",
       "3       1246.5           5.704307              1250             1950   \n",
       "4       1285.7          -5.811404             -3450             4350   \n",
       "..         ...                ...               ...              ...   \n",
       "592     1130.2           0.854383              -300              640   \n",
       "593     1131.0           1.623254              1040             1300   \n",
       "594     1132.4          -3.250548             -1720             1720   \n",
       "595     1129.9          -0.072993               -60             1200   \n",
       "596     1132.5           0.000000               780             1380   \n",
       "\n",
       "     up_or_down  \n",
       "0           1.0  \n",
       "1           1.0  \n",
       "2          -1.0  \n",
       "3           1.0  \n",
       "4          -1.0  \n",
       "..          ...  \n",
       "592         1.0  \n",
       "593         1.0  \n",
       "594        -1.0  \n",
       "595        -1.0  \n",
       "596         0.0  \n",
       "\n",
       "[597 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#필요한 부분을 가져온다\n",
    "stdata = csv_data[[\"start\",\"high\", \"low\",\"end\",\"volume\",\"foreign\", \"person\",\"company\",\"wondollar\"]]\n",
    "stdata.head()\n",
    "\n",
    "#전일대비 가격 변화율을 추가한다\n",
    "price_change = -np.diff(stdata[\"end\"].to_numpy())\n",
    "price = stdata[\"end\"].to_numpy()\n",
    "price = price[1:]\n",
    "price_change_rate = (price_change/price)*100\n",
    "price_change_rate=np.append(price_change_rate,[0])\n",
    "stdata['price_change_rate'] = price_change_rate\n",
    "\n",
    "#캔들 (종가,시가,고가,저가) 관련 정보를 추가한다\n",
    "#시가-종가\n",
    "start = stdata[\"start\"].to_numpy()\n",
    "end = stdata[\"end\"].to_numpy()\n",
    "candle_end_start = end-start\n",
    "stdata['candle_end_start'] = candle_end_start\n",
    "\n",
    "#고가-저가 (당일변동폭) \n",
    "high = stdata[\"high\"].to_numpy()\n",
    "low = stdata[\"low\"].to_numpy()\n",
    "candle_high_low = high-low\n",
    "stdata['candle_high_low'] = candle_high_low\n",
    "\n",
    "\n",
    "#상승or하락 표시 상승:1 보함:0 하락:-1\n",
    "up_or_down = np.zeros(597)\n",
    "\n",
    "price_change_rate = stdata[\"price_change_rate\"].to_numpy()\n",
    "for idx, val in enumerate(price_change_rate):\n",
    "    if val>0:\n",
    "        up_or_down[idx]=1\n",
    "    if val<0:\n",
    "        up_or_down[idx]=-1\n",
    "stdata['up_or_down'] = up_or_down\n",
    "\n",
    "stdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_change_rate</th>\n",
       "      <th>candle_end_start</th>\n",
       "      <th>candle_high_low</th>\n",
       "      <th>up_or_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.620873</td>\n",
       "      <td>-300</td>\n",
       "      <td>2450</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.470588</td>\n",
       "      <td>3100</td>\n",
       "      <td>3900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.387665</td>\n",
       "      <td>-100</td>\n",
       "      <td>1150</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.704307</td>\n",
       "      <td>1250</td>\n",
       "      <td>1950</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.811404</td>\n",
       "      <td>-3450</td>\n",
       "      <td>4350</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0.854383</td>\n",
       "      <td>-300</td>\n",
       "      <td>640</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>1.623254</td>\n",
       "      <td>1040</td>\n",
       "      <td>1300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>-3.250548</td>\n",
       "      <td>-1720</td>\n",
       "      <td>1720</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-0.072993</td>\n",
       "      <td>-60</td>\n",
       "      <td>1200</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>780</td>\n",
       "      <td>1380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price_change_rate  candle_end_start  candle_high_low  up_or_down\n",
       "0             3.620873              -300             2450         1.0\n",
       "1            10.470588              3100             3900         1.0\n",
       "2            -6.387665              -100             1150        -1.0\n",
       "3             5.704307              1250             1950         1.0\n",
       "4            -5.811404             -3450             4350        -1.0\n",
       "..                 ...               ...              ...         ...\n",
       "592           0.854383              -300              640         1.0\n",
       "593           1.623254              1040             1300         1.0\n",
       "594          -3.250548             -1720             1720        -1.0\n",
       "595          -0.072993               -60             1200        -1.0\n",
       "596           0.000000               780             1380         0.0\n",
       "\n",
       "[597 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#사용할 feature를 선택한다\n",
    "\n",
    "input_data = stdata[[\"price_change_rate\",\"candle_end_start\",\"candle_high_low\",\"up_or_down\"]]\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규화 안할경우\n",
    "input_arr = input_data.to_numpy()\n",
    "input_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "fitted = scaler.fit(input_data)\n",
    "input_arr = scaler.transform(input_data)\n",
    "input_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(597, 4)\n"
     ]
    }
   ],
   "source": [
    "#역순\n",
    "input_arr = np.flip(input_arr, axis=0)\n",
    "print(input_arr.shape)\n",
    "#input_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(596,)\n"
     ]
    }
   ],
   "source": [
    "#정답추출\n",
    "up_or_down_ans = input_arr[:,3]\n",
    "\n",
    "up_or_down_ans = up_or_down_ans[1:]\n",
    "print(up_or_down_ans.shape)\n",
    "#up_or_down_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(596, 4)\n"
     ]
    }
   ],
   "source": [
    "#마지막 행은 정답이 없어 버린다\n",
    "input_arr = input_arr[:-1]\n",
    "print(input_arr.shape)\n",
    "#input_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587, 10, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1일 -> len_of_day일 단위의 데이터로 변환 \n",
    "len_of_day =10\n",
    "feature_count = input_arr.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#596일의 데이터로 10일짜리 데이터를 생성하면 596-10+1=587 개의 데이터가 생성된다\n",
    "input_data_count = input_arr.shape[0]-len_of_day+1\n",
    "\n",
    "\n",
    "\n",
    "#596*6열     [[feature갯수 개], \n",
    "#             [feature갯수개], \n",
    "#             [feature갯수개],\n",
    "#             [feature갯수개],\n",
    "#              ... ]\n",
    "#\n",
    "# \n",
    "#              을 [    [ [feature갯수],[feature갯수],[feature갯수]..........[feature갯수] (feature갯수개짜리 n일) ],\n",
    "#                [ (feature갯수짜리 n일개) ],\n",
    "#                [ (13개짜리 n일개) ],\n",
    "#               .\n",
    "#               .\n",
    "#               . \n",
    "#               582개 \n",
    "#    \n",
    "#            ]  ( 582  ,10(일수) , 6(feature갯수) )    형태로 만들어야 한다\n",
    "\n",
    "\n",
    "#inputdata1 : 10일 짜리 데이터 생성 \n",
    "\n",
    "inputdata1 = np.empty((input_data_count,len_of_day,feature_count), dtype=np.float64)\n",
    "\n",
    "for i in range(input_data_count):\n",
    "    for j in range(len_of_day):\n",
    "        inputdata1[i][j]=input_arr[i+j]\n",
    "        \n",
    "inputdata1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(587,)\n",
      "(587, 1)\n"
     ]
    }
   ],
   "source": [
    "up_or_down_ans = up_or_down_ans[len_of_day - 1:]\n",
    "print(up_or_down_ans.shape)\n",
    "up_or_down_ans=up_or_down_ans.reshape(-1,1)\n",
    "print(up_or_down_ans.shape)\n",
    "#up_or_down_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#up_or_down_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(up_or_down_ans) :\n",
    "    if data <0.6:\n",
    "        up_or_down_ans[idx] = 0\n",
    "#up_or_down_ans       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_or_down_ans = up_or_down_ans.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 : inputdata1   (587, 10, 6))\n",
    "#정답 : up_or_down_ans (587,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train : 500 test : 87\n",
    "inputdata1_train = inputdata1[:500]\n",
    "inputdata1_test = inputdata1[500:]\n",
    "\n",
    "up_or_down_train = up_or_down_ans[:500]\n",
    "up_or_down_test =up_or_down_ans[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    self.x_data = inputdata1_train\n",
    "    self.y_data = up_or_down_train\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.tensor(self.x_data[idx])\n",
    "    y = torch.tensor(self.y_data[idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    self.x_data = inputdata1_test\n",
    "    self.y_data = up_or_down_test\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.tensor(self.x_data[idx])\n",
    "    y = torch.tensor(self.y_data[idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset()\n",
    "test_dataset = TestDataset()\n",
    "dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 갯수\n",
    "input_size = feature_count\n",
    "\n",
    "#output size 바로 결과 예측을 위해서 1로 설정 \n",
    "hidden_dim = 2\n",
    "\n",
    "batch_size = 1 \n",
    "\n",
    "# 15일\n",
    "sequence_length = len_of_day\n",
    "\n",
    "# one layer rnn이다.\n",
    "n_layers = 1\n",
    "\n",
    "#inputs = (batch_size * seq_len * input_size ) 인 행렬\\\n",
    "#hidden = (num_layers * batch_size * hidden_size ) 인 행렬\n",
    "#output = (batch,seq_len,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상승 또는 하락 판별 모델\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim,output_size ,n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        #self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        h0 = self.init_hidden(batch_size)\n",
    "        #c0 = self.init_hidden(batch_size)\n",
    "        \n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        \n",
    "        #out = self.fc(out)\n",
    "        #out = out[:,-1,:].view(1,1,1)\n",
    "        return out[:,-1,:],\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.rand(self.n_layers, batch_size, self.hidden_dim)\n",
    "        hidden = nn.init.xavier_normal_(hidden).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 초기화\n",
    "model = Model(input_size, hidden_dim, output_size=1, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "nb_epochs = 240\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "lossval:  0.6494936959310011\n",
      "train acc:  0.492\n",
      "test acc: 0.5\n",
      "epoch:  1\n",
      "lossval:  0.6221974416212602\n",
      "train acc:  0.53\n",
      "test acc: 0.5625\n",
      "epoch:  2\n",
      "lossval:  0.6453410983085632\n",
      "train acc:  0.522\n",
      "test acc: 0.5125\n",
      "epoch:  3\n",
      "lossval:  0.635381339896809\n",
      "train acc:  0.494\n",
      "test acc: 0.5\n",
      "epoch:  4\n",
      "lossval:  0.6123970411040566\n",
      "train acc:  0.506\n",
      "test acc: 0.5\n",
      "epoch:  5\n",
      "lossval:  0.6323812950741161\n",
      "train acc:  0.504\n",
      "test acc: 0.5\n",
      "epoch:  6\n",
      "lossval:  0.6322639671238985\n",
      "train acc:  0.496\n",
      "test acc: 0.5\n",
      "epoch:  7\n",
      "lossval:  0.6311506748199462\n",
      "train acc:  0.512\n",
      "test acc: 0.5\n",
      "epoch:  8\n",
      "lossval:  0.6280718890103427\n",
      "train acc:  0.512\n",
      "test acc: 0.4875\n",
      "epoch:  9\n",
      "lossval:  0.6254908778450706\n",
      "train acc:  0.508\n",
      "test acc: 0.5\n",
      "epoch:  10\n",
      "lossval:  0.6303348974748091\n",
      "train acc:  0.5\n",
      "test acc: 0.5\n",
      "epoch:  11\n",
      "lossval:  0.6311094815080817\n",
      "train acc:  0.5\n",
      "test acc: 0.5\n",
      "epoch:  12\n",
      "lossval:  0.6320569222623652\n",
      "train acc:  0.522\n",
      "test acc: 0.575\n",
      "epoch:  13\n",
      "lossval:  0.6299511432647705\n",
      "train acc:  0.536\n",
      "test acc: 0.575\n",
      "epoch:  14\n",
      "lossval:  0.629755378853191\n",
      "train acc:  0.498\n",
      "test acc: 0.5\n",
      "epoch:  15\n",
      "lossval:  0.629174221645702\n",
      "train acc:  0.518\n",
      "test acc: 0.575\n",
      "epoch:  16\n",
      "lossval:  0.6327536788853731\n",
      "train acc:  0.518\n",
      "test acc: 0.5375\n",
      "epoch:  17\n",
      "lossval:  0.6323241212151267\n",
      "train acc:  0.514\n",
      "test acc: 0.55\n",
      "epoch:  18\n",
      "lossval:  0.6315380399877375\n",
      "train acc:  0.518\n",
      "test acc: 0.525\n",
      "epoch:  19\n",
      "lossval:  0.6298714616081932\n",
      "train acc:  0.514\n",
      "test acc: 0.5\n",
      "epoch:  20\n",
      "lossval:  0.6291666464372114\n",
      "train acc:  0.508\n",
      "test acc: 0.525\n",
      "epoch:  21\n",
      "lossval:  0.6305175716226751\n",
      "train acc:  0.51\n",
      "test acc: 0.4875\n",
      "epoch:  22\n",
      "lossval:  0.629229427467693\n",
      "train acc:  0.518\n",
      "test acc: 0.5625\n",
      "epoch:  23\n",
      "lossval:  0.6280932242220099\n",
      "train acc:  0.502\n",
      "test acc: 0.525\n",
      "epoch:  24\n",
      "lossval:  0.6305836796760559\n",
      "train acc:  0.5\n",
      "test acc: 0.4875\n",
      "epoch:  25\n",
      "lossval:  0.6325771743601019\n",
      "train acc:  0.506\n",
      "test acc: 0.475\n",
      "epoch:  26\n",
      "lossval:  0.6286123319105669\n",
      "train acc:  0.502\n",
      "test acc: 0.4875\n",
      "epoch:  27\n",
      "lossval:  0.6328721068122171\n",
      "train acc:  0.476\n",
      "test acc: 0.4375\n",
      "epoch:  28\n",
      "lossval:  0.6242751652544195\n",
      "train acc:  0.504\n",
      "test acc: 0.4625\n",
      "epoch:  29\n",
      "lossval:  0.6272696776823564\n",
      "train acc:  0.488\n",
      "test acc: 0.425\n",
      "epoch:  30\n",
      "lossval:  0.6377280896360223\n",
      "train acc:  0.506\n",
      "test acc: 0.4875\n",
      "epoch:  31\n",
      "lossval:  0.6178195227276195\n",
      "train acc:  0.514\n",
      "test acc: 0.5\n",
      "epoch:  32\n",
      "lossval:  0.6099779800935226\n",
      "train acc:  0.486\n",
      "test acc: 0.425\n",
      "epoch:  33\n",
      "lossval:  0.6328179359436035\n",
      "train acc:  0.518\n",
      "test acc: 0.4375\n",
      "epoch:  34\n",
      "lossval:  0.619916418465701\n",
      "train acc:  0.518\n",
      "test acc: 0.4375\n",
      "epoch:  35\n",
      "lossval:  0.6146935820579529\n",
      "train acc:  0.5\n",
      "test acc: 0.4375\n",
      "epoch:  36\n",
      "lossval:  0.62639836398038\n",
      "train acc:  0.5\n",
      "test acc: 0.4875\n",
      "epoch:  37\n",
      "lossval:  0.6175340988419272\n",
      "train acc:  0.52\n",
      "test acc: 0.4625\n",
      "epoch:  38\n",
      "lossval:  0.6191411495208741\n",
      "train acc:  0.516\n",
      "test acc: 0.4625\n",
      "epoch:  39\n",
      "lossval:  0.6058440208435059\n",
      "train acc:  0.508\n",
      "test acc: 0.425\n",
      "epoch:  40\n",
      "lossval:  0.6018382029099898\n",
      "train acc:  0.508\n",
      "test acc: 0.5\n",
      "epoch:  41\n",
      "lossval:  0.6230744155970487\n",
      "train acc:  0.516\n",
      "test acc: 0.45\n",
      "epoch:  42\n",
      "lossval:  0.6015508023175327\n",
      "train acc:  0.49\n",
      "test acc: 0.425\n",
      "epoch:  43\n",
      "lossval:  0.6323020295663313\n",
      "train acc:  0.512\n",
      "test acc: 0.4375\n",
      "epoch:  44\n",
      "lossval:  0.5931966239755804\n",
      "train acc:  0.504\n",
      "test acc: 0.5\n",
      "epoch:  45\n",
      "lossval:  0.6270311442288485\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  46\n",
      "lossval:  0.6328396775505759\n",
      "train acc:  0.498\n",
      "test acc: 0.5125\n",
      "epoch:  47\n",
      "lossval:  0.62560481374914\n",
      "train acc:  0.518\n",
      "test acc: 0.4625\n",
      "epoch:  48\n",
      "lossval:  0.6141420158472928\n",
      "train acc:  0.504\n",
      "test acc: 0.4375\n",
      "epoch:  49\n",
      "lossval:  0.6230179699984464\n",
      "train acc:  0.516\n",
      "test acc: 0.4625\n",
      "epoch:  50\n",
      "lossval:  0.6302159244363958\n",
      "train acc:  0.518\n",
      "test acc: 0.5\n",
      "epoch:  51\n",
      "lossval:  0.610254454612732\n",
      "train acc:  0.522\n",
      "test acc: 0.45\n",
      "epoch:  52\n",
      "lossval:  0.6303631695834073\n",
      "train acc:  0.52\n",
      "test acc: 0.45\n",
      "epoch:  53\n",
      "lossval:  0.6122465393759987\n",
      "train acc:  0.514\n",
      "test acc: 0.5125\n",
      "epoch:  54\n",
      "lossval:  0.6206051284616644\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  55\n",
      "lossval:  0.617733645439148\n",
      "train acc:  0.522\n",
      "test acc: 0.4625\n",
      "epoch:  56\n",
      "lossval:  0.6333666021173651\n",
      "train acc:  0.528\n",
      "test acc: 0.475\n",
      "epoch:  57\n",
      "lossval:  0.638996084169908\n",
      "train acc:  0.512\n",
      "test acc: 0.4875\n",
      "epoch:  58\n",
      "lossval:  0.6284528537230059\n",
      "train acc:  0.52\n",
      "test acc: 0.525\n",
      "epoch:  59\n",
      "lossval:  0.637088580565019\n",
      "train acc:  0.526\n",
      "test acc: 0.4625\n",
      "epoch:  60\n",
      "lossval:  0.6430156003345143\n",
      "train acc:  0.516\n",
      "test acc: 0.525\n",
      "epoch:  61\n",
      "lossval:  0.6609805378046902\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  62\n",
      "lossval:  0.5986132307486101\n",
      "train acc:  0.512\n",
      "test acc: 0.5\n",
      "epoch:  63\n",
      "lossval:  0.6495327754454179\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  64\n",
      "lossval:  0.6095225214958191\n",
      "train acc:  0.51\n",
      "test acc: 0.4875\n",
      "epoch:  65\n",
      "lossval:  0.6330946337093006\n",
      "train acc:  0.516\n",
      "test acc: 0.525\n",
      "epoch:  66\n",
      "lossval:  0.6235073685646058\n",
      "train acc:  0.514\n",
      "test acc: 0.525\n",
      "epoch:  67\n",
      "lossval:  0.6200964542952451\n",
      "train acc:  0.514\n",
      "test acc: 0.525\n",
      "epoch:  68\n",
      "lossval:  0.62948139147325\n",
      "train acc:  0.52\n",
      "test acc: 0.5125\n",
      "epoch:  69\n",
      "lossval:  0.6145412445068359\n",
      "train acc:  0.522\n",
      "test acc: 0.5375\n",
      "epoch:  70\n",
      "lossval:  0.6135464484041387\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  71\n",
      "lossval:  0.6309393720193343\n",
      "train acc:  0.514\n",
      "test acc: 0.525\n",
      "epoch:  72\n",
      "lossval:  0.6074652606790716\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  73\n",
      "lossval:  0.5733641104264693\n",
      "train acc:  0.518\n",
      "test acc: 0.4875\n",
      "epoch:  74\n",
      "lossval:  0.6153579419309443\n",
      "train acc:  0.518\n",
      "test acc: 0.525\n",
      "epoch:  75\n",
      "lossval:  0.6111891919916327\n",
      "train acc:  0.514\n",
      "test acc: 0.525\n",
      "epoch:  76\n",
      "lossval:  0.6257959647612138\n",
      "train acc:  0.518\n",
      "test acc: 0.4875\n",
      "epoch:  77\n",
      "lossval:  0.5965838345614347\n",
      "train acc:  0.522\n",
      "test acc: 0.5\n",
      "epoch:  78\n",
      "lossval:  0.6138093336061998\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  79\n",
      "lossval:  0.6313321211121299\n",
      "train acc:  0.516\n",
      "test acc: 0.525\n",
      "epoch:  80\n",
      "lossval:  0.6288532636382363\n",
      "train acc:  0.516\n",
      "test acc: 0.525\n",
      "epoch:  81\n",
      "lossval:  0.65358238436959\n",
      "train acc:  0.52\n",
      "test acc: 0.4875\n",
      "epoch:  82\n",
      "lossval:  0.6140273592688821\n",
      "train acc:  0.522\n",
      "test acc: 0.525\n",
      "epoch:  83\n",
      "lossval:  0.6156147772615607\n",
      "train acc:  0.524\n",
      "test acc: 0.5125\n",
      "epoch:  84\n",
      "lossval:  0.6372848684137518\n",
      "train acc:  0.52\n",
      "test acc: 0.525\n",
      "epoch:  85\n",
      "lossval:  0.6220656795935198\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  86\n",
      "lossval:  0.6048828233372081\n",
      "train acc:  0.518\n",
      "test acc: 0.525\n",
      "epoch:  87\n",
      "lossval:  0.6255233450369402\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  88\n",
      "lossval:  0.6017855069854042\n",
      "train acc:  0.522\n",
      "test acc: 0.5125\n",
      "epoch:  89\n",
      "lossval:  0.6239762111143632\n",
      "train acc:  0.522\n",
      "test acc: 0.5125\n",
      "epoch:  90\n",
      "lossval:  0.572899527983232\n",
      "train acc:  0.522\n",
      "test acc: 0.525\n",
      "epoch:  91\n",
      "lossval:  0.5899282065304843\n",
      "train acc:  0.524\n",
      "test acc: 0.525\n",
      "epoch:  92\n",
      "lossval:  0.6397250045429577\n",
      "train acc:  0.522\n",
      "test acc: 0.525\n",
      "epoch:  93\n",
      "lossval:  0.5861056848005815\n",
      "train acc:  0.522\n",
      "test acc: 0.525\n",
      "epoch:  94\n",
      "lossval:  0.5842248006300492\n",
      "train acc:  0.534\n",
      "test acc: 0.4875\n",
      "epoch:  95\n",
      "lossval:  0.5783370278098366\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  96\n",
      "lossval:  0.6209927038712935\n",
      "train acc:  0.524\n",
      "test acc: 0.5125\n",
      "epoch:  97\n",
      "lossval:  0.6286250623789701\n",
      "train acc:  0.512\n",
      "test acc: 0.525\n",
      "epoch:  98\n",
      "lossval:  0.6195442416451195\n",
      "train acc:  0.524\n",
      "test acc: 0.525\n",
      "epoch:  99\n",
      "lossval:  0.6067485321651805\n",
      "train acc:  0.52\n",
      "test acc: 0.5125\n",
      "epoch:  100\n",
      "lossval:  0.6083302519538186\n",
      "train acc:  0.52\n",
      "test acc: 0.5125\n",
      "epoch:  101\n",
      "lossval:  0.6237710259177468\n",
      "train acc:  0.522\n",
      "test acc: 0.5125\n",
      "epoch:  102\n",
      "lossval:  0.6443563721396707\n",
      "train acc:  0.52\n",
      "test acc: 0.5\n",
      "epoch:  103\n",
      "lossval:  0.6318715474822304\n",
      "train acc:  0.52\n",
      "test acc: 0.5125\n",
      "epoch:  104\n",
      "lossval:  0.5812057863582264\n",
      "train acc:  0.522\n",
      "test acc: 0.525\n",
      "epoch:  105\n",
      "lossval:  0.6354272679849104\n",
      "train acc:  0.526\n",
      "test acc: 0.525\n",
      "epoch:  106\n",
      "lossval:  0.6254854928363454\n",
      "train acc:  0.526\n",
      "test acc: 0.5125\n",
      "epoch:  107\n",
      "lossval:  0.5992712172594937\n",
      "train acc:  0.522\n",
      "test acc: 0.4875\n",
      "epoch:  108\n",
      "lossval:  0.6190946600653908\n",
      "train acc:  0.524\n",
      "test acc: 0.5\n",
      "epoch:  109\n",
      "lossval:  0.6297128449786793\n",
      "train acc:  0.522\n",
      "test acc: 0.5125\n",
      "epoch:  110\n",
      "lossval:  0.5975592223080721\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossval:  0.5882934093475342\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  112\n",
      "lossval:  0.6242512020197781\n",
      "train acc:  0.524\n",
      "test acc: 0.5125\n",
      "epoch:  113\n",
      "lossval:  0.6179681376977401\n",
      "train acc:  0.52\n",
      "test acc: 0.5\n",
      "epoch:  114\n",
      "lossval:  0.5989734302867543\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  115\n",
      "lossval:  0.6427033592354168\n",
      "train acc:  0.524\n",
      "test acc: 0.475\n",
      "epoch:  116\n",
      "lossval:  0.6154251824725758\n",
      "train acc:  0.526\n",
      "test acc: 0.525\n",
      "epoch:  117\n",
      "lossval:  0.6036216898397966\n",
      "train acc:  0.52\n",
      "test acc: 0.525\n",
      "epoch:  118\n",
      "lossval:  0.6166645776141774\n",
      "train acc:  0.524\n",
      "test acc: 0.525\n",
      "epoch:  119\n",
      "lossval:  0.618855805830522\n",
      "train acc:  0.528\n",
      "test acc: 0.525\n",
      "epoch:  120\n",
      "lossval:  0.624544806913896\n",
      "train acc:  0.526\n",
      "test acc: 0.5125\n",
      "epoch:  121\n",
      "lossval:  0.620246532830325\n",
      "train acc:  0.524\n",
      "test acc: 0.5125\n",
      "epoch:  122\n",
      "lossval:  0.6183014815503901\n",
      "train acc:  0.52\n",
      "test acc: 0.5\n",
      "epoch:  123\n",
      "lossval:  0.6165112376213073\n",
      "train acc:  0.522\n",
      "test acc: 0.5\n",
      "epoch:  124\n",
      "lossval:  0.6195665500380776\n",
      "train acc:  0.522\n",
      "test acc: 0.525\n",
      "epoch:  125\n",
      "lossval:  0.622645931894129\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  126\n",
      "lossval:  0.6031147501685402\n",
      "train acc:  0.524\n",
      "test acc: 0.525\n",
      "epoch:  127\n",
      "lossval:  0.5902581182393161\n",
      "train acc:  0.52\n",
      "test acc: 0.5125\n",
      "epoch:  128\n",
      "lossval:  0.6502331137657166\n",
      "train acc:  0.516\n",
      "test acc: 0.5\n",
      "epoch:  129\n",
      "lossval:  0.6229437215761705\n",
      "train acc:  0.518\n",
      "test acc: 0.5\n",
      "epoch:  130\n",
      "lossval:  0.5929067871787331\n",
      "train acc:  0.526\n",
      "test acc: 0.5125\n",
      "epoch:  131\n",
      "lossval:  0.6177252758633006\n",
      "train acc:  0.522\n",
      "test acc: 0.5\n",
      "epoch:  132\n",
      "lossval:  0.613616553219882\n",
      "train acc:  0.518\n",
      "test acc: 0.5\n",
      "epoch:  133\n",
      "lossval:  0.6427849747917869\n",
      "train acc:  0.52\n",
      "test acc: 0.5\n",
      "epoch:  134\n",
      "lossval:  0.6153277906504544\n",
      "train acc:  0.522\n",
      "test acc: 0.5125\n",
      "epoch:  135\n",
      "lossval:  0.5876799908551302\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  136\n",
      "lossval:  0.6104953115636652\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  137\n",
      "lossval:  0.6127107262611389\n",
      "train acc:  0.52\n",
      "test acc: 0.525\n",
      "epoch:  138\n",
      "lossval:  0.6231330329721624\n",
      "train acc:  0.526\n",
      "test acc: 0.5125\n",
      "epoch:  139\n",
      "lossval:  0.6024318380789323\n",
      "train acc:  0.524\n",
      "test acc: 0.5125\n",
      "epoch:  140\n",
      "lossval:  0.6008092175830494\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  141\n",
      "lossval:  0.615778182853352\n",
      "train acc:  0.522\n",
      "test acc: 0.5\n",
      "epoch:  142\n",
      "lossval:  0.5989582321860574\n",
      "train acc:  0.526\n",
      "test acc: 0.5125\n",
      "epoch:  143\n",
      "lossval:  0.6163864916021173\n",
      "train acc:  0.524\n",
      "test acc: 0.5125\n",
      "epoch:  144\n",
      "lossval:  0.604184686053883\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  145\n",
      "lossval:  0.6052337082949552\n",
      "train acc:  0.51\n",
      "test acc: 0.5125\n",
      "epoch:  146\n",
      "lossval:  0.6149135979739102\n",
      "train acc:  0.518\n",
      "test acc: 0.525\n",
      "epoch:  147\n",
      "lossval:  0.5969421657648953\n",
      "train acc:  0.53\n",
      "test acc: 0.5\n",
      "epoch:  148\n",
      "lossval:  0.6099126967516812\n",
      "train acc:  0.52\n",
      "test acc: 0.5\n",
      "epoch:  149\n",
      "lossval:  0.6123705181208524\n",
      "train acc:  0.53\n",
      "test acc: 0.475\n",
      "epoch:  150\n",
      "lossval:  0.6312040697444569\n",
      "train acc:  0.518\n",
      "test acc: 0.5125\n",
      "epoch:  151\n",
      "lossval:  0.6039886463772167\n",
      "train acc:  0.516\n",
      "test acc: 0.5125\n",
      "epoch:  152\n",
      "lossval:  0.5997403188185259\n",
      "train acc:  0.518\n",
      "test acc: 0.5\n",
      "epoch:  153\n",
      "lossval:  0.6135398973118175\n",
      "train acc:  0.524\n",
      "test acc: 0.5125\n",
      "epoch:  154\n",
      "lossval:  0.6513350410894914\n",
      "train acc:  0.526\n",
      "test acc: 0.4875\n",
      "epoch:  155\n",
      "lossval:  0.5739684495058927\n",
      "train acc:  0.534\n",
      "test acc: 0.5\n",
      "epoch:  156\n",
      "lossval:  0.578025851466439\n",
      "train acc:  0.562\n",
      "test acc: 0.5375\n",
      "epoch:  157\n",
      "lossval:  0.5764849711548198\n",
      "train acc:  0.526\n",
      "test acc: 0.5\n",
      "epoch:  158\n",
      "lossval:  0.6277942158959129\n",
      "train acc:  0.566\n",
      "test acc: 0.55\n",
      "epoch:  159\n",
      "lossval:  0.6293257951736451\n",
      "train acc:  0.558\n",
      "test acc: 0.5875\n",
      "epoch:  160\n",
      "lossval:  0.5921568025242199\n",
      "train acc:  0.556\n",
      "test acc: 0.5625\n",
      "epoch:  161\n",
      "lossval:  0.6180253744125366\n",
      "train acc:  0.554\n",
      "test acc: 0.5875\n",
      "epoch:  162\n",
      "lossval:  0.5729351303794167\n",
      "train acc:  0.554\n",
      "test acc: 0.575\n",
      "epoch:  163\n",
      "lossval:  0.599323593486439\n",
      "train acc:  0.56\n",
      "test acc: 0.5875\n",
      "epoch:  164\n",
      "lossval:  0.5999720335006714\n",
      "train acc:  0.552\n",
      "test acc: 0.5875\n",
      "epoch:  165\n",
      "lossval:  0.6181065895340659\n",
      "train acc:  0.56\n",
      "test acc: 0.575\n",
      "epoch:  166\n",
      "lossval:  0.5784388953989202\n",
      "train acc:  0.56\n",
      "test acc: 0.6\n",
      "epoch:  167\n",
      "lossval:  0.6101092403585261\n",
      "train acc:  0.562\n",
      "test acc: 0.5875\n",
      "epoch:  168\n",
      "lossval:  0.6237785512750799\n",
      "train acc:  0.552\n",
      "test acc: 0.6\n",
      "epoch:  169\n",
      "lossval:  0.6111125696789135\n",
      "train acc:  0.568\n",
      "test acc: 0.575\n",
      "epoch:  170\n",
      "lossval:  0.6285218693993309\n",
      "train acc:  0.562\n",
      "test acc: 0.5375\n",
      "epoch:  171\n",
      "lossval:  0.6168139100074768\n",
      "train acc:  0.564\n",
      "test acc: 0.5875\n",
      "epoch:  172\n",
      "lossval:  0.6157284877517006\n",
      "train acc:  0.562\n",
      "test acc: 0.5625\n",
      "epoch:  173\n",
      "lossval:  0.6057187167080966\n",
      "train acc:  0.532\n",
      "test acc: 0.5\n",
      "epoch:  174\n",
      "lossval:  0.6630032268437472\n",
      "train acc:  0.566\n",
      "test acc: 0.5125\n",
      "epoch:  175\n",
      "lossval:  0.637183795192025\n",
      "train acc:  0.558\n",
      "test acc: 0.55\n",
      "epoch:  176\n",
      "lossval:  0.6215350237759677\n",
      "train acc:  0.564\n",
      "test acc: 0.6\n",
      "epoch:  177\n",
      "lossval:  0.6313074350357055\n",
      "train acc:  0.538\n",
      "test acc: 0.525\n",
      "epoch:  178\n",
      "lossval:  0.6061801910400391\n",
      "train acc:  0.574\n",
      "test acc: 0.5375\n",
      "epoch:  179\n",
      "lossval:  0.6338446487079967\n",
      "train acc:  0.56\n",
      "test acc: 0.5375\n",
      "epoch:  180\n",
      "lossval:  0.6222812977704135\n",
      "train acc:  0.562\n",
      "test acc: 0.575\n",
      "epoch:  181\n",
      "lossval:  0.5828810930252075\n",
      "train acc:  0.566\n",
      "test acc: 0.575\n",
      "epoch:  182\n",
      "lossval:  0.6247569430958141\n",
      "train acc:  0.558\n",
      "test acc: 0.55\n",
      "epoch:  183\n",
      "lossval:  0.6279702663421631\n",
      "train acc:  0.55\n",
      "test acc: 0.575\n",
      "epoch:  184\n",
      "lossval:  0.6139869397336787\n",
      "train acc:  0.558\n",
      "test acc: 0.55\n",
      "epoch:  185\n",
      "lossval:  0.6462321942502802\n",
      "train acc:  0.572\n",
      "test acc: 0.575\n",
      "epoch:  186\n",
      "lossval:  0.6425627957690846\n",
      "train acc:  0.554\n",
      "test acc: 0.5625\n",
      "epoch:  187\n",
      "lossval:  0.6008906136859548\n",
      "train acc:  0.56\n",
      "test acc: 0.575\n",
      "epoch:  188\n",
      "lossval:  0.5996767011555758\n",
      "train acc:  0.558\n",
      "test acc: 0.575\n",
      "epoch:  189\n",
      "lossval:  0.5994693528522145\n",
      "train acc:  0.554\n",
      "test acc: 0.5375\n",
      "epoch:  190\n",
      "lossval:  0.5837566050616178\n",
      "train acc:  0.56\n",
      "test acc: 0.575\n",
      "epoch:  191\n",
      "lossval:  0.6002171207558025\n",
      "train acc:  0.568\n",
      "test acc: 0.5625\n",
      "epoch:  192\n",
      "lossval:  0.5768256555904042\n",
      "train acc:  0.564\n",
      "test acc: 0.55\n",
      "epoch:  193\n",
      "lossval:  0.6184217203747142\n",
      "train acc:  0.558\n",
      "test acc: 0.5875\n",
      "epoch:  194\n",
      "lossval:  0.6033538807522166\n",
      "train acc:  0.572\n",
      "test acc: 0.575\n",
      "epoch:  195\n",
      "lossval:  0.5584502285177058\n",
      "train acc:  0.554\n",
      "test acc: 0.5375\n",
      "epoch:  196\n",
      "lossval:  0.5815556022253904\n",
      "train acc:  0.554\n",
      "test acc: 0.55\n",
      "epoch:  197\n",
      "lossval:  0.6392355355349454\n",
      "train acc:  0.558\n",
      "test acc: 0.5375\n",
      "epoch:  198\n",
      "lossval:  0.5829265572808006\n",
      "train acc:  0.554\n",
      "test acc: 0.5625\n",
      "epoch:  199\n",
      "lossval:  0.6102914441715587\n",
      "train acc:  0.568\n",
      "test acc: 0.5375\n",
      "epoch:  200\n",
      "lossval:  0.5875160856680437\n",
      "train acc:  0.548\n",
      "test acc: 0.5375\n",
      "epoch:  201\n",
      "lossval:  0.5997676004063\n",
      "train acc:  0.56\n",
      "test acc: 0.5375\n",
      "epoch:  202\n",
      "lossval:  0.6267209193923257\n",
      "train acc:  0.554\n",
      "test acc: 0.5625\n",
      "epoch:  203\n",
      "lossval:  0.6207974845712835\n",
      "train acc:  0.554\n",
      "test acc: 0.55\n",
      "epoch:  204\n",
      "lossval:  0.5981628580526872\n",
      "train acc:  0.566\n",
      "test acc: 0.5375\n",
      "epoch:  205\n",
      "lossval:  0.5781663417816162\n",
      "train acc:  0.566\n",
      "test acc: 0.525\n",
      "epoch:  206\n",
      "lossval:  0.595069755749269\n",
      "train acc:  0.566\n",
      "test acc: 0.5375\n",
      "epoch:  207\n",
      "lossval:  0.6231412193991921\n",
      "train acc:  0.554\n",
      "test acc: 0.5625\n",
      "epoch:  208\n",
      "lossval:  0.6284799098968505\n",
      "train acc:  0.568\n",
      "test acc: 0.5375\n",
      "epoch:  209\n",
      "lossval:  0.6582803238521923\n",
      "train acc:  0.57\n",
      "test acc: 0.525\n",
      "epoch:  210\n",
      "lossval:  0.5660609711300243\n",
      "train acc:  0.554\n",
      "test acc: 0.5625\n",
      "epoch:  211\n",
      "lossval:  0.6025837378068404\n",
      "train acc:  0.564\n",
      "test acc: 0.525\n",
      "epoch:  212\n",
      "lossval:  0.5948371876369823\n",
      "train acc:  0.542\n",
      "test acc: 0.5375\n",
      "epoch:  213\n",
      "lossval:  0.6474778099493547\n",
      "train acc:  0.548\n",
      "test acc: 0.55\n",
      "epoch:  214\n",
      "lossval:  0.6331443266435103\n",
      "train acc:  0.562\n",
      "test acc: 0.5375\n",
      "epoch:  215\n",
      "lossval:  0.5881476824933832\n",
      "train acc:  0.582\n",
      "test acc: 0.5625\n",
      "epoch:  216\n",
      "lossval:  0.6168383359909058\n",
      "train acc:  0.566\n",
      "test acc: 0.525\n",
      "epoch:  217\n",
      "lossval:  0.6500024513764815\n",
      "train acc:  0.562\n",
      "test acc: 0.55\n",
      "epoch:  218\n",
      "lossval:  0.6299275484952059\n",
      "train acc:  0.56\n",
      "test acc: 0.5375\n",
      "epoch:  219\n",
      "lossval:  0.587736620686271\n",
      "train acc:  0.56\n",
      "test acc: 0.55\n",
      "epoch:  220\n",
      "lossval:  0.6053044384176081\n",
      "train acc:  0.562\n",
      "test acc: 0.55\n",
      "epoch:  221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossval:  0.6079375462098555\n",
      "train acc:  0.566\n",
      "test acc: 0.5375\n",
      "epoch:  222\n",
      "lossval:  0.618220224163749\n",
      "train acc:  0.576\n",
      "test acc: 0.55\n",
      "epoch:  223\n",
      "lossval:  0.6084708983247931\n",
      "train acc:  0.564\n",
      "test acc: 0.5125\n",
      "epoch:  224\n",
      "lossval:  0.6394104594534094\n",
      "train acc:  0.558\n",
      "test acc: 0.55\n",
      "epoch:  225\n",
      "lossval:  0.6180222565477544\n",
      "train acc:  0.558\n",
      "test acc: 0.5625\n",
      "epoch:  226\n",
      "lossval:  0.6379308299584823\n",
      "train acc:  0.554\n",
      "test acc: 0.5375\n",
      "epoch:  227\n",
      "lossval:  0.6101654572920365\n",
      "train acc:  0.566\n",
      "test acc: 0.575\n",
      "epoch:  228\n",
      "lossval:  0.64444654638117\n",
      "train acc:  0.556\n",
      "test acc: 0.525\n",
      "epoch:  229\n",
      "lossval:  0.6292249327356165\n",
      "train acc:  0.55\n",
      "test acc: 0.5125\n",
      "epoch:  230\n",
      "lossval:  0.5992926998571916\n",
      "train acc:  0.558\n",
      "test acc: 0.55\n",
      "epoch:  231\n",
      "lossval:  0.6244922453706915\n",
      "train acc:  0.556\n",
      "test acc: 0.5125\n",
      "epoch:  232\n",
      "lossval:  0.6127253380688754\n",
      "train acc:  0.554\n",
      "test acc: 0.5375\n",
      "epoch:  233\n",
      "lossval:  0.6544364235617898\n",
      "train acc:  0.56\n",
      "test acc: 0.525\n",
      "epoch:  234\n",
      "lossval:  0.6416705662553961\n",
      "train acc:  0.558\n",
      "test acc: 0.5625\n",
      "epoch:  235\n",
      "lossval:  0.639474787495353\n",
      "train acc:  0.562\n",
      "test acc: 0.575\n",
      "epoch:  236\n",
      "lossval:  0.6173023288900202\n",
      "train acc:  0.558\n",
      "test acc: 0.55\n",
      "epoch:  237\n",
      "lossval:  0.616542514887723\n",
      "train acc:  0.556\n",
      "test acc: 0.55\n",
      "epoch:  238\n",
      "lossval:  0.5890148802237077\n",
      "train acc:  0.552\n",
      "test acc: 0.525\n",
      "epoch:  239\n",
      "lossval:  0.6190262989564376\n",
      "train acc:  0.548\n",
      "test acc: 0.525\n",
      "epoch:  240\n",
      "lossval:  0.592530585419048\n",
      "train acc:  0.558\n",
      "test acc: 0.525\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "#for epoch in range(nb_epochs + 1):\n",
    "#     for batch_idx, samples in enumerate(dataloader):\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    print(\"epoch: \", epoch)\n",
    "    lossval=0\n",
    "    for batch_idx, (input_data,label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_data = input_data.float().to(device)\n",
    "        label = label.view(-1).long().to(device)\n",
    "        output, = model(input_data)\n",
    "        #print(input_data.shape)\n",
    "        #print(output.shape)\n",
    "        #print(label.shape)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx%10==0):\n",
    "            #print(\"epoch: \",epoch, \"  iter:\",batch_idx,\"/502\")\n",
    "            #print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "            lossval += loss.item()\n",
    "            #print(\"\")\n",
    "    print(\"lossval: \", lossval/55.0 )\n",
    "    trainAcc(500)\n",
    "    testAcc(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc:  0.59\n"
     ]
    }
   ],
   "source": [
    "#train acc\n",
    "#trainsize= 500.0\n",
    "def trainAcc(trainsize):\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        for i in range(int(trainsize)):\n",
    "            ip, ans = train_dataset.__getitem__(i)\n",
    "            ip = ip.float().view(-1,10,feature_count).to(device)\n",
    "            output, = model(ip)\n",
    "            a,p = torch.max(output,1)\n",
    "            if(p.item() == ans.item()):\n",
    "                count += 1\n",
    "                #print(\"right\")\n",
    "        acc = count*1.0/trainsize\n",
    "        print(\"train acc: \",acc)\n",
    "        \n",
    "trainAcc(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.5\n"
     ]
    }
   ],
   "source": [
    "#test acc \n",
    "#testsize = 80\n",
    "\n",
    "def testAcc(testsize):\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        for i in range(int(testsize)):\n",
    "            ip, ans = test_dataset.__getitem__(i)\n",
    "            ip = ip.float().view(-1,10,feature_count).to(device)\n",
    "            output, = model(ip)\n",
    "            a,p = torch.max(output,1)\n",
    "            if(p.item() == ans.item()):\n",
    "                count += 1\n",
    "                #print(\"right\")\n",
    "        acc = count*1.0/testsize\n",
    "        print(\"test acc:\", acc)\n",
    "        \n",
    "testAcc(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsize= 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
