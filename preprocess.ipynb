{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>start</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>end</th>\n",
       "      <th>volume</th>\n",
       "      <th>foreign</th>\n",
       "      <th>person</th>\n",
       "      <th>company</th>\n",
       "      <th>wondollar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020.3.25</td>\n",
       "      <td>48950</td>\n",
       "      <td>49600</td>\n",
       "      <td>47150</td>\n",
       "      <td>48650</td>\n",
       "      <td>52735922</td>\n",
       "      <td>-2751527</td>\n",
       "      <td>4980190</td>\n",
       "      <td>-1695448</td>\n",
       "      <td>1229.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.3.24</td>\n",
       "      <td>43850</td>\n",
       "      <td>46950</td>\n",
       "      <td>43050</td>\n",
       "      <td>46950</td>\n",
       "      <td>49801908</td>\n",
       "      <td>2929769</td>\n",
       "      <td>-6174614</td>\n",
       "      <td>3254324</td>\n",
       "      <td>1249.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.3.23</td>\n",
       "      <td>42600</td>\n",
       "      <td>43550</td>\n",
       "      <td>42400</td>\n",
       "      <td>42500</td>\n",
       "      <td>41701626</td>\n",
       "      <td>-8143293</td>\n",
       "      <td>10988297</td>\n",
       "      <td>-3248991</td>\n",
       "      <td>1266.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.3.20</td>\n",
       "      <td>44150</td>\n",
       "      <td>45500</td>\n",
       "      <td>43550</td>\n",
       "      <td>45400</td>\n",
       "      <td>49730008</td>\n",
       "      <td>-5133212</td>\n",
       "      <td>3248749</td>\n",
       "      <td>1669124</td>\n",
       "      <td>1246.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.3.19</td>\n",
       "      <td>46400</td>\n",
       "      <td>46650</td>\n",
       "      <td>42300</td>\n",
       "      <td>42950</td>\n",
       "      <td>56925513</td>\n",
       "      <td>-5807616</td>\n",
       "      <td>4105594</td>\n",
       "      <td>1612440</td>\n",
       "      <td>1285.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>2017.10.23</td>\n",
       "      <td>54600</td>\n",
       "      <td>54640</td>\n",
       "      <td>54000</td>\n",
       "      <td>54300</td>\n",
       "      <td>8311050</td>\n",
       "      <td>30468</td>\n",
       "      <td>4568</td>\n",
       "      <td>-63065</td>\n",
       "      <td>1130.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2017.10.20</td>\n",
       "      <td>52800</td>\n",
       "      <td>54100</td>\n",
       "      <td>52800</td>\n",
       "      <td>53840</td>\n",
       "      <td>8027050</td>\n",
       "      <td>29906</td>\n",
       "      <td>-2283</td>\n",
       "      <td>-39735</td>\n",
       "      <td>1131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>2017.10.19</td>\n",
       "      <td>54700</td>\n",
       "      <td>54700</td>\n",
       "      <td>52980</td>\n",
       "      <td>52980</td>\n",
       "      <td>12108700</td>\n",
       "      <td>-19892</td>\n",
       "      <td>46171</td>\n",
       "      <td>-46270</td>\n",
       "      <td>1132.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>2017.10.18</td>\n",
       "      <td>54820</td>\n",
       "      <td>55240</td>\n",
       "      <td>54040</td>\n",
       "      <td>54760</td>\n",
       "      <td>10110750</td>\n",
       "      <td>8951</td>\n",
       "      <td>-3285</td>\n",
       "      <td>-23873</td>\n",
       "      <td>1129.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>2017.10.17</td>\n",
       "      <td>54020</td>\n",
       "      <td>55380</td>\n",
       "      <td>54000</td>\n",
       "      <td>54800</td>\n",
       "      <td>10607800</td>\n",
       "      <td>34020</td>\n",
       "      <td>-15898</td>\n",
       "      <td>-35696</td>\n",
       "      <td>1132.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  start   high    low    end    volume  foreign    person  \\\n",
       "0     2020.3.25  48950  49600  47150  48650  52735922 -2751527   4980190   \n",
       "1     2020.3.24  43850  46950  43050  46950  49801908  2929769  -6174614   \n",
       "2     2020.3.23  42600  43550  42400  42500  41701626 -8143293  10988297   \n",
       "3     2020.3.20  44150  45500  43550  45400  49730008 -5133212   3248749   \n",
       "4     2020.3.19  46400  46650  42300  42950  56925513 -5807616   4105594   \n",
       "..          ...    ...    ...    ...    ...       ...      ...       ...   \n",
       "592  2017.10.23  54600  54640  54000  54300   8311050    30468      4568   \n",
       "593  2017.10.20  52800  54100  52800  53840   8027050    29906     -2283   \n",
       "594  2017.10.19  54700  54700  52980  52980  12108700   -19892     46171   \n",
       "595  2017.10.18  54820  55240  54040  54760  10110750     8951     -3285   \n",
       "596  2017.10.17  54020  55380  54000  54800  10607800    34020    -15898   \n",
       "\n",
       "     company  wondollar  \n",
       "0   -1695448     1229.9  \n",
       "1    3254324     1249.6  \n",
       "2   -3248991     1266.5  \n",
       "3    1669124     1246.5  \n",
       "4    1612440     1285.7  \n",
       "..       ...        ...  \n",
       "592   -63065     1130.2  \n",
       "593   -39735     1131.0  \n",
       "594   -46270     1132.4  \n",
       "595   -23873     1129.9  \n",
       "596   -35696     1132.5  \n",
       "\n",
       "[597 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "'''\n",
    "data preprocessing\n",
    "'''\n",
    "\n",
    "#주가데이터 파일을 로드\n",
    "csv_data = pd.read_csv(\"./data/005930_200325.csv\")\n",
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>end</th>\n",
       "      <th>volume</th>\n",
       "      <th>foreign</th>\n",
       "      <th>person</th>\n",
       "      <th>company</th>\n",
       "      <th>wondollar</th>\n",
       "      <th>price_change_rate</th>\n",
       "      <th>candle_end_start</th>\n",
       "      <th>candle_high_low</th>\n",
       "      <th>up_or_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48950</td>\n",
       "      <td>49600</td>\n",
       "      <td>47150</td>\n",
       "      <td>48650</td>\n",
       "      <td>52735922</td>\n",
       "      <td>-2751527</td>\n",
       "      <td>4980190</td>\n",
       "      <td>-1695448</td>\n",
       "      <td>1229.9</td>\n",
       "      <td>3.620873</td>\n",
       "      <td>-300</td>\n",
       "      <td>2450</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43850</td>\n",
       "      <td>46950</td>\n",
       "      <td>43050</td>\n",
       "      <td>46950</td>\n",
       "      <td>49801908</td>\n",
       "      <td>2929769</td>\n",
       "      <td>-6174614</td>\n",
       "      <td>3254324</td>\n",
       "      <td>1249.6</td>\n",
       "      <td>10.470588</td>\n",
       "      <td>3100</td>\n",
       "      <td>3900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42600</td>\n",
       "      <td>43550</td>\n",
       "      <td>42400</td>\n",
       "      <td>42500</td>\n",
       "      <td>41701626</td>\n",
       "      <td>-8143293</td>\n",
       "      <td>10988297</td>\n",
       "      <td>-3248991</td>\n",
       "      <td>1266.5</td>\n",
       "      <td>-6.387665</td>\n",
       "      <td>-100</td>\n",
       "      <td>1150</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44150</td>\n",
       "      <td>45500</td>\n",
       "      <td>43550</td>\n",
       "      <td>45400</td>\n",
       "      <td>49730008</td>\n",
       "      <td>-5133212</td>\n",
       "      <td>3248749</td>\n",
       "      <td>1669124</td>\n",
       "      <td>1246.5</td>\n",
       "      <td>5.704307</td>\n",
       "      <td>1250</td>\n",
       "      <td>1950</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46400</td>\n",
       "      <td>46650</td>\n",
       "      <td>42300</td>\n",
       "      <td>42950</td>\n",
       "      <td>56925513</td>\n",
       "      <td>-5807616</td>\n",
       "      <td>4105594</td>\n",
       "      <td>1612440</td>\n",
       "      <td>1285.7</td>\n",
       "      <td>-5.811404</td>\n",
       "      <td>-3450</td>\n",
       "      <td>4350</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>54600</td>\n",
       "      <td>54640</td>\n",
       "      <td>54000</td>\n",
       "      <td>54300</td>\n",
       "      <td>8311050</td>\n",
       "      <td>30468</td>\n",
       "      <td>4568</td>\n",
       "      <td>-63065</td>\n",
       "      <td>1130.2</td>\n",
       "      <td>0.854383</td>\n",
       "      <td>-300</td>\n",
       "      <td>640</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>52800</td>\n",
       "      <td>54100</td>\n",
       "      <td>52800</td>\n",
       "      <td>53840</td>\n",
       "      <td>8027050</td>\n",
       "      <td>29906</td>\n",
       "      <td>-2283</td>\n",
       "      <td>-39735</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>1.623254</td>\n",
       "      <td>1040</td>\n",
       "      <td>1300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>54700</td>\n",
       "      <td>54700</td>\n",
       "      <td>52980</td>\n",
       "      <td>52980</td>\n",
       "      <td>12108700</td>\n",
       "      <td>-19892</td>\n",
       "      <td>46171</td>\n",
       "      <td>-46270</td>\n",
       "      <td>1132.4</td>\n",
       "      <td>-3.250548</td>\n",
       "      <td>-1720</td>\n",
       "      <td>1720</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>54820</td>\n",
       "      <td>55240</td>\n",
       "      <td>54040</td>\n",
       "      <td>54760</td>\n",
       "      <td>10110750</td>\n",
       "      <td>8951</td>\n",
       "      <td>-3285</td>\n",
       "      <td>-23873</td>\n",
       "      <td>1129.9</td>\n",
       "      <td>-0.072993</td>\n",
       "      <td>-60</td>\n",
       "      <td>1200</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>54020</td>\n",
       "      <td>55380</td>\n",
       "      <td>54000</td>\n",
       "      <td>54800</td>\n",
       "      <td>10607800</td>\n",
       "      <td>34020</td>\n",
       "      <td>-15898</td>\n",
       "      <td>-35696</td>\n",
       "      <td>1132.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>780</td>\n",
       "      <td>1380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start   high    low    end    volume  foreign    person  company  \\\n",
       "0    48950  49600  47150  48650  52735922 -2751527   4980190 -1695448   \n",
       "1    43850  46950  43050  46950  49801908  2929769  -6174614  3254324   \n",
       "2    42600  43550  42400  42500  41701626 -8143293  10988297 -3248991   \n",
       "3    44150  45500  43550  45400  49730008 -5133212   3248749  1669124   \n",
       "4    46400  46650  42300  42950  56925513 -5807616   4105594  1612440   \n",
       "..     ...    ...    ...    ...       ...      ...       ...      ...   \n",
       "592  54600  54640  54000  54300   8311050    30468      4568   -63065   \n",
       "593  52800  54100  52800  53840   8027050    29906     -2283   -39735   \n",
       "594  54700  54700  52980  52980  12108700   -19892     46171   -46270   \n",
       "595  54820  55240  54040  54760  10110750     8951     -3285   -23873   \n",
       "596  54020  55380  54000  54800  10607800    34020    -15898   -35696   \n",
       "\n",
       "     wondollar  price_change_rate  candle_end_start  candle_high_low  \\\n",
       "0       1229.9           3.620873              -300             2450   \n",
       "1       1249.6          10.470588              3100             3900   \n",
       "2       1266.5          -6.387665              -100             1150   \n",
       "3       1246.5           5.704307              1250             1950   \n",
       "4       1285.7          -5.811404             -3450             4350   \n",
       "..         ...                ...               ...              ...   \n",
       "592     1130.2           0.854383              -300              640   \n",
       "593     1131.0           1.623254              1040             1300   \n",
       "594     1132.4          -3.250548             -1720             1720   \n",
       "595     1129.9          -0.072993               -60             1200   \n",
       "596     1132.5           0.000000               780             1380   \n",
       "\n",
       "     up_or_down  \n",
       "0           1.0  \n",
       "1           1.0  \n",
       "2          -1.0  \n",
       "3           1.0  \n",
       "4          -1.0  \n",
       "..          ...  \n",
       "592         1.0  \n",
       "593         1.0  \n",
       "594        -1.0  \n",
       "595        -1.0  \n",
       "596         0.0  \n",
       "\n",
       "[597 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#필요한 부분을 가져온다\n",
    "stdata = csv_data[[\"start\",\"high\", \"low\",\"end\",\"volume\",\"foreign\", \"person\",\"company\",\"wondollar\"]]\n",
    "stdata.head()\n",
    "\n",
    "#전일대비 가격 변화율을 추가한다\n",
    "price_change = -np.diff(stdata[\"end\"].to_numpy())\n",
    "price = stdata[\"end\"].to_numpy()\n",
    "price = price[1:]\n",
    "price_change_rate = (price_change/price)*100\n",
    "price_change_rate=np.append(price_change_rate,[0])\n",
    "stdata['price_change_rate'] = price_change_rate\n",
    "\n",
    "#전일대비 거래량 변화율을 추가한다\n",
    "\n",
    "\n",
    "#캔들 (종가,시가,고가,저가) 관련 정보를 추가한다\n",
    "#시가-종가\n",
    "start = stdata[\"start\"].to_numpy()\n",
    "end = stdata[\"end\"].to_numpy()\n",
    "candle_end_start = end-start\n",
    "stdata['candle_end_start'] = candle_end_start\n",
    "\n",
    "#고가-저가 (당일변동폭) \n",
    "high = stdata[\"high\"].to_numpy()\n",
    "low = stdata[\"low\"].to_numpy()\n",
    "candle_high_low = high-low\n",
    "stdata['candle_high_low'] = candle_high_low\n",
    "\n",
    "\n",
    "#상승or하락 표시 상승:1 보함:0 하락:-1\n",
    "up_or_down = np.zeros(597)\n",
    "\n",
    "price_change_rate = stdata[\"price_change_rate\"].to_numpy()\n",
    "for idx, val in enumerate(price_change_rate):\n",
    "    if val>0:\n",
    "        up_or_down[idx]=1\n",
    "    if val<0:\n",
    "        up_or_down[idx]=-1\n",
    "stdata['up_or_down'] = up_or_down\n",
    "\n",
    "stdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "fitted = scaler.fit(stdata)\n",
    "stdata_arr = scaler.transform(stdata)\n",
    "stdata_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정답1 : 가격변화강도 = 가격 변화율 절대값\n",
    "price_change = -np.diff(stdata[\"end\"].to_numpy())\n",
    "\n",
    "price = stdata[\"end\"].to_numpy()\n",
    "price = price[1:]\n",
    "\n",
    "price_change_rate = (price_change/price)*100\n",
    "price_change_power = abs(price_change_rate)\n",
    "\n",
    "price_change_power.shape\n",
    "#3.62087327, 10.47058824,  6.3876652 ,  5.70430733,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정답2 : 상승(변화율>0) or 하락 \n",
    "#상승일경우 1 하락일경우 0\n",
    "\n",
    "up_or_down = np.zeros(596)\n",
    "\n",
    "price_change = -np.diff(stdata[\"end\"].to_numpy())\n",
    "for idx, val in enumerate(price_change):\n",
    "    if val>0:\n",
    "        up_or_down[idx]=1\n",
    "\n",
    "up_or_down.shape\n",
    "#1., 1., 0., 1., 0., 0., 0., 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputdata1 : 15일 짜리 데이터 생성 \n",
    "\n",
    "#0행은 버린다 (정답이없기떄문)\n",
    "#596일의 데이터로 15일짜리 데이터를 생성하면 596-15+1=582 개의 데이터가 생성된다\n",
    "stdata_arr=stdata_arr[1:]\n",
    "stdata_arr\n",
    "\n",
    "input_data_count = stdata_arr.shape[0]-15+1\n",
    "\n",
    "\n",
    "#596*13열     [[13개], \n",
    "#             [13개], \n",
    "#             [13개],\n",
    "#             [13개],\n",
    "#              ... ]\n",
    "#\n",
    "# \n",
    "#              을 [    [ [13개],[13개],[13개]..........[13개] (13개짜리 15개) ],\n",
    "#                [ [13개],[13개],[13개]..........[13개] (13개짜리 15개) ],\n",
    "#                [ [13개],[13개],[13개]..........[13개] (13개짜리 15개) ],\n",
    "#               .\n",
    "#               .\n",
    "#               . \n",
    "#               582개 \n",
    "#    \n",
    "#            ]  (582,15,13)    형태로 만들어야 한다\n",
    "\n",
    "#for row in stdata_arr:\n",
    "#    for elem in row \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdata1 = np.empty((582,15,13), dtype=np.float64)\n",
    "\n",
    "for i in range(input_data_count):\n",
    "    for j in range(15):\n",
    "        inputdata1[i][j]=stdata_arr[i+j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582, 15, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputdata1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch cross entry loss 에서는 target(정답)을 one hot encode 허자 얺음\n",
    "#from sklearn import preprocessing\n",
    "\n",
    "#(하락,상승)으로 one hot encoding\n",
    "#\n",
    "#up_or_down=up_or_down.astype(np.int64)\n",
    "#num = np.unique(up_or_down, axis=0)\n",
    "#num = num.shape[0]\n",
    "\n",
    "#answer1 = np.eye(num)[up_or_down]\n",
    "#answer1 = answer1[:582]\n",
    "#answer1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_or_down=up_or_down.astype(np.int)\n",
    "up_or_down=up_or_down[:582]\n",
    "up_or_down = up_or_down.reshape(-1,1)\n",
    "up_or_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train : 502 test : 80\n",
    "inputdata1_train = inputdata1[:502]\n",
    "inputdata1_test = inputdata1[502:]\n",
    "\n",
    "up_or_down_train = up_or_down[:502]\n",
    "up_or_down_test = up_or_down[502:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    self.x_data = inputdata1_train\n",
    "    self.y_data = up_or_down_train\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.tensor(self.x_data[idx])\n",
    "    y = torch.tensor(self.y_data[idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    self.x_data = inputdata1_test\n",
    "    self.y_data = up_or_down_test\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.tensor(self.x_data[idx])\n",
    "    y = torch.tensor(self.y_data[idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset()\n",
    "test_dataset = TestDataset()\n",
    "dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 갯수\n",
    "input_size = 13\n",
    "\n",
    "#output from the cell. 바로 결과 예측을 위해서 2로 설정 \n",
    "hidden_dim = 1\n",
    "\n",
    "batch_size = 1 \n",
    "\n",
    "# 15일\n",
    "sequence_length = 15\n",
    "\n",
    "# one layer rnn이다.\n",
    "n_layers = 1 \n",
    "\n",
    "#inputs = (batch_size * seq_len * input_size ) 인 행렬\\\n",
    "#hidden = (num_layers * batch_size * hidden_size ) 인 행렬\n",
    "#output = (batch,seq_len,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상승 또는 하락 판별 모델\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        #self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        #out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상승 또는 하락 판별 모델\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        #self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        h0 = self.init_hidden(batch_size)\n",
    "        c0 = self.init_hidden(batch_size)\n",
    "        \n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, (hn,cn) = self.rnn(x, (h0,c0))\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        #out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        #out = self.fc(out)\n",
    "        \n",
    "        return out,\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.rand(self.n_layers, batch_size, self.hidden_dim)\n",
    "        hidden = nn.init.xavier_normal_(hidden).to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 초기화\n",
    "model = Model(input_size=13, hidden_dim=1, n_layers=3)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "nb_epochs = 20\n",
    "lr=0.005\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  0   iter: 0 /502\n",
      "Loss: 2.6571\n",
      "\n",
      "epoch:  0   iter: 10 /502\n",
      "Loss: 2.4346\n",
      "\n",
      "epoch:  0   iter: 20 /502\n",
      "Loss: 2.6396\n",
      "\n",
      "epoch:  0   iter: 30 /502\n",
      "Loss: 2.6470\n",
      "\n",
      "epoch:  0   iter: 40 /502\n",
      "Loss: 2.6773\n",
      "\n",
      "epoch:  0   iter: 50 /502\n",
      "Loss: 2.4878\n",
      "\n",
      "epoch:  0   iter: 60 /502\n",
      "Loss: 2.4947\n",
      "\n",
      "epoch:  0   iter: 70 /502\n",
      "Loss: 2.5672\n",
      "\n",
      "epoch:  0   iter: 80 /502\n",
      "Loss: 2.5059\n",
      "\n",
      "epoch:  0   iter: 90 /502\n",
      "Loss: 2.4564\n",
      "\n",
      "epoch:  0   iter: 100 /502\n",
      "Loss: 2.7719\n",
      "\n",
      "epoch:  0   iter: 110 /502\n",
      "Loss: 2.4840\n",
      "\n",
      "epoch:  0   iter: 120 /502\n",
      "Loss: 2.3883\n",
      "\n",
      "epoch:  0   iter: 130 /502\n",
      "Loss: 2.7157\n",
      "\n",
      "epoch:  0   iter: 140 /502\n",
      "Loss: 2.5230\n",
      "\n",
      "epoch:  0   iter: 150 /502\n",
      "Loss: 2.0872\n",
      "\n",
      "epoch:  0   iter: 160 /502\n",
      "Loss: 2.6520\n",
      "\n",
      "epoch:  0   iter: 170 /502\n",
      "Loss: 2.1174\n",
      "\n",
      "epoch:  0   iter: 180 /502\n",
      "Loss: 1.9034\n",
      "\n",
      "epoch:  0   iter: 190 /502\n",
      "Loss: 2.3076\n",
      "\n",
      "epoch:  0   iter: 200 /502\n",
      "Loss: 2.0202\n",
      "\n",
      "epoch:  0   iter: 210 /502\n",
      "Loss: 2.0299\n",
      "\n",
      "epoch:  0   iter: 220 /502\n",
      "Loss: 2.1579\n",
      "\n",
      "epoch:  0   iter: 230 /502\n",
      "Loss: 1.9496\n",
      "\n",
      "epoch:  0   iter: 240 /502\n",
      "Loss: 2.4766\n",
      "\n",
      "epoch:  0   iter: 250 /502\n",
      "Loss: 1.8888\n",
      "\n",
      "epoch:  0   iter: 260 /502\n",
      "Loss: 2.6608\n",
      "\n",
      "epoch:  0   iter: 270 /502\n",
      "Loss: 2.3363\n",
      "\n",
      "epoch:  0   iter: 280 /502\n",
      "Loss: 2.2489\n",
      "\n",
      "epoch:  0   iter: 290 /502\n",
      "Loss: 2.3819\n",
      "\n",
      "epoch:  0   iter: 300 /502\n",
      "Loss: 2.3839\n",
      "\n",
      "epoch:  0   iter: 310 /502\n",
      "Loss: 1.8176\n",
      "\n",
      "epoch:  0   iter: 320 /502\n",
      "Loss: 2.3075\n",
      "\n",
      "epoch:  0   iter: 330 /502\n",
      "Loss: 2.5306\n",
      "\n",
      "epoch:  0   iter: 340 /502\n",
      "Loss: 2.0313\n",
      "\n",
      "epoch:  0   iter: 350 /502\n",
      "Loss: 2.6193\n",
      "\n",
      "epoch:  0   iter: 360 /502\n",
      "Loss: 1.9221\n",
      "\n",
      "epoch:  0   iter: 370 /502\n",
      "Loss: 2.4870\n",
      "\n",
      "epoch:  0   iter: 380 /502\n",
      "Loss: 2.5446\n",
      "\n",
      "epoch:  0   iter: 390 /502\n",
      "Loss: 2.4940\n",
      "\n",
      "epoch:  0   iter: 400 /502\n",
      "Loss: 2.0208\n",
      "\n",
      "epoch:  0   iter: 410 /502\n",
      "Loss: 2.4374\n",
      "\n",
      "epoch:  0   iter: 420 /502\n",
      "Loss: 1.9860\n",
      "\n",
      "epoch:  0   iter: 430 /502\n",
      "Loss: 2.4867\n",
      "\n",
      "epoch:  0   iter: 440 /502\n",
      "Loss: 2.0814\n",
      "\n",
      "epoch:  0   iter: 450 /502\n",
      "Loss: 1.7835\n",
      "\n",
      "epoch:  0   iter: 460 /502\n",
      "Loss: 2.1492\n",
      "\n",
      "epoch:  0   iter: 470 /502\n",
      "Loss: 2.3876\n",
      "\n",
      "epoch:  0   iter: 480 /502\n",
      "Loss: 2.4246\n",
      "\n",
      "epoch:  0   iter: 490 /502\n",
      "Loss: 2.4573\n",
      "\n",
      "epoch:  0   iter: 500 /502\n",
      "Loss: 2.0607\n",
      "\n",
      "epoch:  1\n",
      "epoch:  1   iter: 0 /502\n",
      "Loss: 1.9557\n",
      "\n",
      "epoch:  1   iter: 10 /502\n",
      "Loss: 2.4227\n",
      "\n",
      "epoch:  1   iter: 20 /502\n",
      "Loss: 2.0782\n",
      "\n",
      "epoch:  1   iter: 30 /502\n",
      "Loss: 1.9450\n",
      "\n",
      "epoch:  1   iter: 40 /502\n",
      "Loss: 1.9139\n",
      "\n",
      "epoch:  1   iter: 50 /502\n",
      "Loss: 2.2781\n",
      "\n",
      "epoch:  1   iter: 60 /502\n",
      "Loss: 2.3035\n",
      "\n",
      "epoch:  1   iter: 70 /502\n",
      "Loss: 2.0444\n",
      "\n",
      "epoch:  1   iter: 80 /502\n",
      "Loss: 2.3371\n",
      "\n",
      "epoch:  1   iter: 90 /502\n",
      "Loss: 2.1153\n",
      "\n",
      "epoch:  1   iter: 100 /502\n",
      "Loss: 2.2230\n",
      "\n",
      "epoch:  1   iter: 110 /502\n",
      "Loss: 2.4128\n",
      "\n",
      "epoch:  1   iter: 120 /502\n",
      "Loss: 1.9528\n",
      "\n",
      "epoch:  1   iter: 130 /502\n",
      "Loss: 1.9908\n",
      "\n",
      "epoch:  1   iter: 140 /502\n",
      "Loss: 1.7692\n",
      "\n",
      "epoch:  1   iter: 150 /502\n",
      "Loss: 2.6090\n",
      "\n",
      "epoch:  1   iter: 160 /502\n",
      "Loss: 1.8854\n",
      "\n",
      "epoch:  1   iter: 170 /502\n",
      "Loss: 2.2023\n",
      "\n",
      "epoch:  1   iter: 180 /502\n",
      "Loss: 1.9335\n",
      "\n",
      "epoch:  1   iter: 190 /502\n",
      "Loss: 1.8649\n",
      "\n",
      "epoch:  1   iter: 200 /502\n",
      "Loss: 2.1720\n",
      "\n",
      "epoch:  1   iter: 210 /502\n",
      "Loss: 2.0660\n",
      "\n",
      "epoch:  1   iter: 220 /502\n",
      "Loss: 1.8395\n",
      "\n",
      "epoch:  1   iter: 230 /502\n",
      "Loss: 1.9568\n",
      "\n",
      "epoch:  1   iter: 240 /502\n",
      "Loss: 1.8262\n",
      "\n",
      "epoch:  1   iter: 250 /502\n",
      "Loss: 2.1833\n",
      "\n",
      "epoch:  1   iter: 260 /502\n",
      "Loss: 2.3620\n",
      "\n",
      "epoch:  1   iter: 270 /502\n",
      "Loss: 1.8424\n",
      "\n",
      "epoch:  1   iter: 280 /502\n",
      "Loss: 2.4396\n",
      "\n",
      "epoch:  1   iter: 290 /502\n",
      "Loss: 1.9564\n",
      "\n",
      "epoch:  1   iter: 300 /502\n",
      "Loss: 2.4630\n",
      "\n",
      "epoch:  1   iter: 310 /502\n",
      "Loss: 2.4215\n",
      "\n",
      "epoch:  1   iter: 320 /502\n",
      "Loss: 2.1127\n",
      "\n",
      "epoch:  1   iter: 330 /502\n",
      "Loss: 1.8906\n",
      "\n",
      "epoch:  1   iter: 340 /502\n",
      "Loss: 1.9841\n",
      "\n",
      "epoch:  1   iter: 350 /502\n",
      "Loss: 1.8939\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-21be9866b739>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-0dc169d55a41>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Initializing hidden state for first input using method defined below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mh0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-0dc169d55a41>\u001b[0m in \u001b[0;36minit_hidden\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# We'll send the tensor holding the hidden state to the device we specified earlier as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_normal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36mxavier_normal_\u001b[1;34m(tensor, gain)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_no_grad_normal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ds\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36m_no_grad_normal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_no_grad_normal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#학습\n",
    "#for epoch in range(nb_epochs + 1):\n",
    "#     for batch_idx, samples in enumerate(dataloader):\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    print(\"epoch: \", epoch)\n",
    "    for batch_idx, (input_data,label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_data = input_data.float().to(device)\n",
    "        label = label.long().to(device)\n",
    "        output, = model(input_data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx%10==0):\n",
    "            print(\"epoch: \",epoch, \"  iter:\",batch_idx,\"/502\")\n",
    "            print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "            print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9554, 0.1795],\n",
       "         [0.5039, 0.5256],\n",
       "         [0.8298, 0.8800]],\n",
       "\n",
       "        [[0.9116, 0.8294],\n",
       "         [0.1725, 0.4755],\n",
       "         [0.3395, 0.5084]],\n",
       "\n",
       "        [[0.4154, 0.0935],\n",
       "         [0.5873, 0.8907],\n",
       "         [0.6696, 0.3904]],\n",
       "\n",
       "        [[0.9994, 0.5405],\n",
       "         [0.5444, 0.4122],\n",
       "         [0.4245, 0.6817]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = torch.rand(4,3,2)\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
